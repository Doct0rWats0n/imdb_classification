{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5817f2-1178-48f9-a669-9320d7ff2c3e",
   "metadata": {},
   "source": [
    "### Гиперпараметры\n",
    "parameters.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e07e4cdf-1c94-404f-8d7d-dd0a86143913",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_DIM, H_DIM = 10, 20\n",
    "TRAINLOADER_PARAMS = {\n",
    "    'batch_size': 4, 'num_workers': 2, 'shuffle': True\n",
    "}\n",
    "TESTLOADER_PARAMS = {\n",
    "    'batch_size': 4, 'num_workers': 2, 'shuffle': False\n",
    "}\n",
    "EPOCHES = 4\n",
    "PATH_TO_DATASET = \"dataset/IMDB Dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efacc67-7450-4279-8ee5-3dbf62786e22",
   "metadata": {},
   "source": [
    "### Модель\n",
    "model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b055d6d3-fdc0-4994-81fa-ec161d755a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, e_dim=E_DIM, h_dim=H_DIM):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(e_dim, h_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(h_dim, h_dim * 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, hs = self.rnn(x)\n",
    "        x = torch.cat((x, hs), dim=1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d06e5-e11d-4f03-b963-2ab135bf8569",
   "metadata": {},
   "source": [
    "### Интерфейс для работы с датасетом\n",
    "data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef64b5c-51fe-41e8-916f-8aa4b90c4a93",
   "metadata": {},
   "source": [
    "#### Старый интерфейс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11bd4af6-fe10-43ed-8f08-d3d33cf47201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchtext.transforms as transforms\n",
    "import csv\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "class IMDB(Dataset):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        with open(path) as file:\n",
    "            csvreader = csv.reader(file, delimiter=',')\n",
    "            self.data = [i for i in csvreader]\n",
    "\n",
    "        # self.label_transform = transforms.Sequential(\n",
    "        #     transforms.LabelToIndex()\n",
    "        # )\n",
    "        # self.tz = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        # self.tokenized_data = []\n",
    "        # for i in self.data:\n",
    "        #     self.tokenized_data += self.tz.tokenize(i[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        value = self.data[index]\n",
    "        item, label = value\n",
    "        item = self.text_to_tensor(item)\n",
    "        return item, label\n",
    "\n",
    "    @staticmethod\n",
    "    def text_to_tensor(text):\n",
    "        char_to_index = {char: idx for idx, char in enumerate(set(text))}\n",
    "        text_indices = [char_to_index[char] for char in text]\n",
    "        tensor = torch.tensor(text_indices, dtype=torch.long)\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f228eb6-fea5-4746-be04-2060d0c792ef",
   "metadata": {},
   "source": [
    "#### Переделанный интерфейс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bc69b2e-a6b2-411d-9733-f412fc30591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import csv\n",
    "\n",
    "\n",
    "class IMDB_full:\n",
    "\n",
    "    def __init__(self, path_to_dataset, split_size=0.5):\n",
    "        super().__init__()\n",
    "        self.full_dataset = self.load_csv(path_to_dataset)\n",
    "        self.split_size = 0.5\n",
    "        self.split_dataset()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.full_dataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_csv(path_to_csv, delimiter=','):\n",
    "        with open(path_to_csv, 'r') as file:\n",
    "            reader = csv.reader(file, delimiter=delimiter)\n",
    "            data = [i for i in reader]\n",
    "        return data\n",
    "\n",
    "    def split_dataset(self):\n",
    "        trainset_size = int(len(self.full_dataset) * self.split_size)\n",
    "        self.trainset, self.testset = random_split(self.full_dataset, (trainset_size, \n",
    "                                                                  len(self.full_dataset) - trainset_size))\n",
    "\n",
    "    def change_split_size(self, new_split_size):\n",
    "        self.split_size = new_split_size\n",
    "        self.split_dataset()\n",
    "\n",
    "    def get_trainloader(self):\n",
    "        return DataLoader(self.trainset, **TRAINLOADER_PARAMS)\n",
    "\n",
    "    def get_testloader(self):\n",
    "        return DataLoader(self.testset, **TESTLOADER_PARAMS)\n",
    "\n",
    "    @staticmethod\n",
    "    def text_to_tensor(text):\n",
    "        char_to_index = {char: idx for idx, char in enumerate(set(text))}\n",
    "        text_indices = [char_to_index[char] for char in text]\n",
    "        tensor = torch.tensor(text_indices, dtype=torch.long)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14616389-0a3e-4ac9-aaeb-e6c334996681",
   "metadata": {},
   "source": [
    "### Интерфейс для обучения\n",
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4cc07f4-055e-497c-8dc6-1bea7f60968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b3d3f57-d580-445a-966b-efe16b758485",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, trainset, testset, epoches=EPOCHES):\n",
    "        self.net = model()\n",
    "        self.epoches = epoches\n",
    "        self.trainset, self.testset = trainset, testset\n",
    "\n",
    "    def set_loss(self, lr=0.01):\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "    def start_learning(self):\n",
    "        for epoch in range(self.epoches):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(self.trainset, 0):\n",
    "                self.optimizer.zero_grad()\n",
    "                inputs, labels = data\n",
    "                output = self.net(inputs)\n",
    "                loss = self.criterion(output, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                if i % 2000 == 1999:  # выводим каждую 2000 мини-батчу\n",
    "                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                    running_loss = 0.0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2c22f-0744-42ab-a9b5-0485536988c6",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41cb61fc-058b-42b2-a2f4-a5ca404ef002",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m learner \u001b[38;5;241m=\u001b[39m Learner(RNN, trainset, testset)\n\u001b[1;32m      5\u001b[0m learner\u001b[38;5;241m.\u001b[39mset_loss()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m, in \u001b[0;36mLearner.start_learning\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, labels)\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x, hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, hs), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:521\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRNN: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    523\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "dataset = IMDB_full(PATH_TO_DATASET)\n",
    "trainset, testset = dataset.get_trainloader(), dataset.get_testloader()\n",
    "\n",
    "learner = Learner(RNN, trainset, testset)\n",
    "learner.set_loss()\n",
    "learner.start_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216fbf8-bfbd-4cee-9048-8ac9c1aaf48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
